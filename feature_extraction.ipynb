{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.15"
    },
    "colab": {
      "name": "feature_extraction.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tpChQkNh8v6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "16725de9-261a-4e0d-901a-83a066e2c6e3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQixcMTViUTs",
        "colab_type": "text"
      },
      "source": [
        "HDF5 CLASS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T26mdu-giJJa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import h5py\n",
        "import os\n",
        "class HDF5DatasetWriter:\n",
        "\tdef __init__(self, dims, outputPath, dataKey=\"images\", bufSize=1000):\n",
        "\t\tif os.path.exists(outputPath):\n",
        "\t\t\traise ValueError(\"Output path exist cannot be overwritten. Manually delete the file before continue\", outputPath)\n",
        "\t\tself.db = h5py.File(outputPath, \"w\")\n",
        "\t\tself.data = self.db.create_dataset(dataKey, dims, dtype=\"float\")\n",
        "\t\tself.labels = self.db.create_dataset(\"labels\", (dims[0],), dtype=\"int\")\n",
        "\t\tself.bufSize = bufSize\n",
        "\t\tself.buffer = {\"data\":[], \"labels\":[]}\n",
        "\t\tself.idx = 0\n",
        "\t\n",
        "\tdef add(self, rows, labels):\n",
        "\t\tself.buffer[\"data\"].extend(rows)\n",
        "\t\tself.buffer[\"labels\"].extend(labels)\n",
        "\t\tif (len(self.buffer[\"data\"]) >= self.bufSize):\n",
        "\t\t\tself.flush()\n",
        "\t\n",
        "\tdef flush(self):\n",
        "\t\ti = self.idx + len(self.buffer[\"data\"])\n",
        "\t\tself.data[self.idx:i] = self.buffer[\"data\"]\n",
        "\t\tself.labels[self.idx:i] = self.buffer[\"labels\"]\n",
        "\t\tself.idx = i\n",
        "\t\tself.buffer = {\"data\":[], \"labels\":[]}\n",
        "\t\n",
        "\tdef storeClassLabels(self, classLabels):\n",
        "\t\tdt = h5py.special_dtype(vlen=str)\n",
        "\t\tlabelSet = self.db.create_dataset(\"label_names\", (len(classLabels), ), dtype=dt)\n",
        "\t\tlabelSet[:] = classLabels\n",
        "\n",
        "\tdef close(self):\n",
        "\t\tif (len(self.buffer[\"data\"])>0):\n",
        "\t\t\tself.flush()\n",
        "\t\tself.db.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_3gss1cnpPI",
        "colab_type": "text"
      },
      "source": [
        "EXTRACTING FEATURE USING VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUk3cMY9ibQd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "11eb83ae-7f8c-4c0c-a404-612859bd8dfa"
      },
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.applications import imagenet_utils\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "#from pyimagesearch.io.hdf5datasetwriter import HDF5DatasetWriter\n",
        "from imutils import paths\n",
        "import numpy as np\n",
        "import progressbar\n",
        "import argparse\n",
        "import random\n",
        "import pandas as pd\n",
        "import os\n",
        "'''\n",
        "from tensorflow.compat.v1 import ConfigProto\n",
        "from tensorflow.compat.v1 import InteractiveSession\n",
        "config = ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "session = InteractiveSession(config=config)\n",
        "ap = argparse.ArgumentParser()\n",
        "ap.add_argument(\"-d\", \"--dataset\", help= \"path to input dataset\")\n",
        "ap.add_argument(\"-o\", \"--output\", help= \"path to output HDF5 dataset\")\n",
        "ap.add_argument(\"-c\", \"--csv\", help = \"path to csv file\")\n",
        "ap.add_argument(\"-b\", \"--batch_size\", type = int, default = 32, help= \"batch size of images to be passed through network\")\n",
        "ap.add_argument(\"-s\", \"--buffer_size\", type= int, default = 1000, help= \"size of feature extraction buffer\")\n",
        "args = vars(ap.parse_args())\n",
        "bs = args[\"batch_size\"]\n",
        "'''\n",
        "bs = 32\n",
        "labels = []\n",
        "\n",
        "'''\n",
        "imagePaths = list(paths.list_images(args[\"dataset\"]))\n",
        "random.shuffle(imagePaths)\n",
        "labels = [p.split(os.path.sep)[-2] for p in imagePaths]\n",
        "'''\n",
        "#After mounting the google drive\n",
        "#something like /content/drive/\n",
        "csvPath = \"/content/drive/My Drive/Colab_Notebooks/python code/flora.csv\"\n",
        "dataset = \"/content/drive/My Drive/cc78ftcdf9-1/\"\n",
        "outPathHDF5 = \"/content/drive/My Drive/Colab_Notebooks/features.hdf5\"\n",
        "\n",
        "dataframe = pd.read_csv(csvPath)\n",
        "allImages = os.listdir(dataset)\n",
        "\n",
        "random.shuffle(allImages)\n",
        "\n",
        "for eachImage in allImages:\n",
        "\tfindDot = eachImage.find('.')\n",
        "\teachImageLabel = dataframe[dataframe[\"ID\"] == int(eachImage[:findDot])]\n",
        "\tlabels.append(eachImageLabel.SPECIES.values[0])\n",
        "le = LabelEncoder()\n",
        "labels = le.fit_transform(labels)\n",
        "\n",
        "print(\"[INFO] loading network...\")\n",
        "model = VGG16(weights=\"imagenet\", include_top = False)\n",
        "\n",
        "dataset = HDF5DatasetWriter((len(allImages), 512 * 7 * 7), outPathHDF5 , dataKey=\"features\", bufSize=1000)\n",
        "dataset.storeClassLabels(le.classes_)\n",
        "\n",
        "widgets = [\"Extracting Features: \", progressbar.Percentage(), \" \", progressbar.Bar(), \" \", progressbar.ETA()]\n",
        "pbar = progressbar.ProgressBar(maxval = len(allImages), widgets = widgets).start()\n",
        "for i in np.arange(0, len(allImages), bs):\n",
        "\tbatchPaths = allImages[i: i + bs]\n",
        "\tbatchLabels = labels[i: i + bs]\n",
        "\tbatchImages = []\n",
        "\t\n",
        "\tfor (j, allImage) in enumerate(batchPaths):\n",
        "\t\timagePath = dataset + allImage\n",
        "\t\timage = load_img(imagePath, target_size=(224, 224))\n",
        "\t\timage = img_to_array(image)\n",
        "\t\timage = np.expand_dims(image, axis=0)\n",
        "\t\timage = imagenet_utils.preprocess_input(image)\n",
        "\t\tbatchImages.append(image)\n",
        "  \n",
        "\tbatchImages = np.vstack(batchImages)\n",
        "\tfeatures = model.predict(batchImages, batch_size=bs)\n",
        "\tfeatures = features.reshape((features.shape[0], 512*7*7))\n",
        "\tdataset.add(features, batchLabels)\n",
        "\tpbar.update(i)\n",
        "dataset.close()\n",
        "pbar.finish()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading network...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting Features: 100% |####################################| Time:  0:26:14\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yd-Fq60jn25j",
        "colab_type": "text"
      },
      "source": [
        "USING GRIDSEARCHCV WITH THE EXTRACTED FEATURES."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4spbs0GjlDs6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        },
        "outputId": "a1c4ec32-ec37-4832-cd6b-cd5ca50ea323"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "import h5py\n",
        "import pickle\n",
        "'''\n",
        "ap = argparse.ArgumentParser()\n",
        "ap.add_argument(\"-d\", \"--db\", help=\"PATH TO HDF5 DATASET\")\n",
        "ap.add_argument(\"-m\", \"--model\", help=\"PATH TO OUTPUT MODEL\")\n",
        "ap.add_argument(\"-j\", \"--jobs\", type=int, default=-1, help= \"# of jobs to run when tuning hyperparameter\")\n",
        "\n",
        "args = vars(ap.parse_args())\n",
        "'''\n",
        "db = h5py.File(\"/content/drive/My Drive/Colab_Notebooks/python code/features.hdf5\",\"r\")\n",
        "i = int(db[\"labels\"].shape[0]*0.75)\n",
        "\n",
        "print(\"[INFO] tuning hyperparameters...\")\n",
        "params = {\"C\": [0.1, 1.0, 10.0]}\n",
        "model = GridSearchCV(LogisticRegression(solver=\"lbfgs\", multi_class=\"auto\", max_iter=10000), params, cv=3, n_jobs=-1)\n",
        "model.fit(db[\"features\"][:i], db[\"labels\"][:i])\n",
        "print(\"[INFO] best hyperparameter: {}\".format(model.best_params_))\n",
        "\n",
        "print(\"[INFO] evaluating...\")\n",
        "preds = model.predict(db[\"features\"][i:])\n",
        "print(classification_report(db[\"labels\"][i:], preds, target_names=db[\"label_names\"]))\n",
        "\n",
        "'''\n",
        "print(\"[INFO] saving model...\")\n",
        "f = open(args[\"model\"], \"wb\")\n",
        "f.write(pickle.dumps(model.best_estimator_))\n",
        "f.close()\n",
        "'''\n",
        "db.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] tuning hyperparameters...\n",
            "[INFO] best hyperparameter: {'C': 1.0}\n",
            "[INFO] evaluating...\n",
            "                             precision    recall  f1-score   support\n",
            "\n",
            "   Acrocarpus fraxinifolius       1.00      1.00      1.00         5\n",
            "     Araucaria angustifolia       1.00      1.00      1.00        17\n",
            "    Aspidosperma polyneuron       1.00      1.00      1.00         5\n",
            "            Aspidosperma sp       1.00      1.00      1.00        10\n",
            "         Bagassa guianensis       1.00      1.00      1.00        16\n",
            "Balfourodendron riedelianum       1.00      1.00      1.00        17\n",
            "       Bertholletia excelsa       1.00      1.00      1.00         8\n",
            "               Bowdichia sp       1.00      1.00      1.00        19\n",
            "     Brosimum parinarioides       1.00      1.00      1.00         7\n",
            "          Carapa guianensis       0.78      1.00      0.88         7\n",
            "     Cariniana estrellensis       1.00      1.00      1.00        12\n",
            "           Cedrela fissilis       1.00      1.00      1.00         9\n",
            "    Cedrelinga cateniformis       1.00      1.00      1.00        19\n",
            "           Cordia goeldiana       1.00      1.00      1.00         7\n",
            "               Couratari sp       1.00      1.00      1.00         9\n",
            "                Dipteryx sp       1.00      1.00      1.00         8\n",
            "           Erisma uncinatum       1.00      1.00      1.00        13\n",
            "              Eucalyptus sp       1.00      1.00      1.00         5\n",
            "         Eugenia pyriformis       1.00      1.00      1.00         6\n",
            "      Euxylophora paraensis       1.00      1.00      1.00        14\n",
            "              Goupia glabra       1.00      1.00      1.00         7\n",
            "          Grevillea robusta       1.00      1.00      1.00        14\n",
            "            Handroanthus sp       1.00      1.00      1.00        11\n",
            "                Hymenaea sp       1.00      1.00      1.00         6\n",
            "      Hymenolobium petraeum       1.00      1.00      1.00         9\n",
            "            Hymenolobium sp       1.00      1.00      1.00         7\n",
            "                  Inga vera       1.00      1.00      1.00         9\n",
            "             Laurus nobilis       1.00      1.00      1.00        13\n",
            "   Machaerium paraguariense       1.00      1.00      1.00         7\n",
            "              Machaerium sp       1.00      1.00      1.00         3\n",
            "            Manilkara elata       1.00      1.00      1.00        11\n",
            "            Melia azedarach       1.00      0.95      0.97        19\n",
            "          Mezilaurus itauba       1.00      1.00      1.00        16\n",
            "       Micropholis venulosa       1.00      1.00      1.00        10\n",
            "           Mimosa scabrella       1.00      0.75      0.86         8\n",
            "        Muellera campestris       1.00      1.00      1.00        10\n",
            "         Myroxylon balsamum       1.00      1.00      1.00         8\n",
            "     Nectandra megapotamica       1.00      1.00      1.00         6\n",
            "            Ocotea indecora       0.83      1.00      0.91         5\n",
            "              Ocotea porosa       1.00      1.00      1.00        13\n",
            "               Peltogyne sp       1.00      1.00      1.00        15\n",
            "                   Pinus sp       1.00      1.00      1.00        13\n",
            "        Pouteria pachycarpa       1.00      1.00      1.00        10\n",
            "            Simarouba amara       1.00      1.00      1.00         5\n",
            "      Swietenia macrophylla       1.00      1.00      1.00        18\n",
            "                Vochysia sp       1.00      1.00      1.00        10\n",
            "\n",
            "                   accuracy                           0.99       476\n",
            "                  macro avg       0.99      0.99      0.99       476\n",
            "               weighted avg       0.99      0.99      0.99       476\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}